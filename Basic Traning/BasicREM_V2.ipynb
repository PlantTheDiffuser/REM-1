{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.2.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.13.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (4.10.0)\n",
      "Requirement already satisfied: sympy in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nicks\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch\n",
    "!pip install torchtyping\n",
    "!pip install stltovoxel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exception (False, 'No lines found, impossible to read')\n",
      "Processing layer 0/6\n",
      "Processing layer 1/6\n",
      "Processing layer 2/6\n",
      "Processing layer 3/6\n",
      "Processing layer 4/6\n",
      "export png 0/8\n",
      "export png 1/8\n",
      "export png 2/8\n",
      "export png 3/8\n",
      "export png 4/8\n",
      "export png 5/8\n",
      "export png 6/8\n",
      "export png 7/8\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'voxel\\\\Cube10x10x10_voxels.png'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m output_voxel_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39msplitext(filename)[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_voxels.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     27\u001b[0m stltovoxel\u001b[38;5;241m.\u001b[39mconvert_file(stl_path, output_voxel_path, resolution)\n\u001b[1;32m---> 28\u001b[0m voxel_graph \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_voxel_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m voxel_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(voxel_graph, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     30\u001b[0m stl\u001b[38;5;241m.\u001b[39mappend(voxel_tensor\u001b[38;5;241m.\u001b[39mflatten())\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'voxel\\\\Cube10x10x10_voxels.png'"
     ]
    }
   ],
   "source": [
    "#STL File Preprocessing\n",
    "import stltovoxel\n",
    "import matplotlib\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtyping import TensorType\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Define the folder containing the STL files\n",
    "stl_folder = 'stl'\n",
    "output_folder = 'voxel'\n",
    "resolution = 100\n",
    "target_width = 100\n",
    "target_height = 100\n",
    "\n",
    "stl = []\n",
    "label = [1, 1, 2]\n",
    "\n",
    "for filename in os.listdir(stl_folder):\n",
    "    if filename.lower().endswith('.stl'):\n",
    "        stl_path = os.path.join(stl_folder, filename)\n",
    "        output_voxel_path = os.path.join(output_folder, os.path.splitext(filename)[0] + '_voxels.png')\n",
    "        stltovoxel.convert_file(stl_path, output_voxel_path, resolution)\n",
    "        voxel_graph = np.load(output_voxel_path)\n",
    "        voxel_tensor = torch.tensor(voxel_graph, dtype=torch.float32)\n",
    "        stl.append(voxel_tensor.flatten())\n",
    "\n",
    "\n",
    "label = torch.tensor(label, dtype=torch.long)\n",
    "stl = torch.stack(stl)\n",
    "\n",
    "dataset = TensorDataset(stl, label)\n",
    "data_loader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Network Block\n",
    "\n",
    "\n",
    "\n",
    "#Input in the form of a voxelized stl file\n",
    "#Output is a number corresponding to a Solidworks Feature\n",
    "#Ex: 0 is none, 1 is boss, 2 is revolve, etc(rest is in notes)\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "class FeatureRecognition(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(0)\n",
    "        self.first_linear = nn.Linear(784, 512)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.projection = nn.Linear(512, 3)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, stl: TensorType[float]) -> TensorType[float]:\n",
    "        torch.manual_seed(0)\n",
    "        stl = stl.flatten()\n",
    "        out = self.sigmoid(self.projection(self.dropout(self.relu(self.first_linear(stl)))))\n",
    "        return torch.round(out, decimals=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Traning block\n",
    "\n",
    "model = FeatureRecognition()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "dataSetSize = 3\n",
    "\n",
    "#Traning loop\n",
    "epochs = 5\n",
    "for i in range(epochs):\n",
    "    for stl, label in data_loader:\n",
    "        stl = stl.view(stl.shape[0], 784)           #FIX\n",
    "\n",
    "        modelPrediction = model(stl)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_function(modelPrediction, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Block\n",
    "\n",
    "model.eval()\n",
    "\n",
    "stl = stl.view(stl.shape[0], 780)               #FIX\n",
    "\n",
    "modelPrediction = model(stl)\n",
    "max = torch.max(modelPrediction, dim = 1)\n",
    "for i in range(len(stl)):\n",
    "    print(max[i].item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
